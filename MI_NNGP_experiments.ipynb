{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYkiCBDNHBcv",
        "outputId": "2959a1a9-819e-437e-f697-099a1718a4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neural-tangents\n",
            "  Downloading neural_tangents-0.6.1-py2.py3-none-any.whl (249 kB)\n",
            "\u001b[K     |████████████████████████████████| 249 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting tf2jax>=0.3.0\n",
            "  Downloading tf2jax-0.3.1-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.3.13 in /usr/local/lib/python3.8/dist-packages (from neural-tangents) (0.3.25)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from neural-tangents) (4.4.0)\n",
            "Collecting frozendict>=2.3\n",
            "  Downloading frozendict-2.3.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (110 kB)\n",
            "\u001b[K     |████████████████████████████████| 110 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.13->neural-tangents) (1.7.3)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.13->neural-tangents) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from jax>=0.3.13->neural-tangents) (1.21.6)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.8/dist-packages (from tf2jax>=0.3.0->neural-tangents) (0.3.25+cuda11.cudnn805)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from tf2jax>=0.3.0->neural-tangents) (2.9.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tf2jax>=0.3.0->neural-tangents) (1.3.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from tf2jax>=0.3.0->neural-tangents) (0.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (57.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (3.19.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (3.1.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.28.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.1.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2.9.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.12)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.51.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow>=2.8.0->tf2jax>=0.3.0->neural-tangents) (3.0.9)\n",
            "Installing collected packages: tf2jax, frozendict, neural-tangents\n",
            "Successfully installed frozendict-2.3.4 neural-tangents-0.6.1 tf2jax-0.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install neural-tangents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import jax.numpy\n",
        "import neural_tangents as nt\n",
        "from neural_tangents import stax\n",
        "from jax import random\n",
        "import math\n",
        "\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import *\n",
        "from sklearn.linear_model import *"
      ],
      "metadata": {
        "id": "z4WRUvOcHMb6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MI_NNGP1(input, number_of_imputation=1, W_std=1.0, b_std=0.0):\n",
        "    # W_std is standard deviation of weight parameters\n",
        "    # b_std is standard deviation of bias parameters\n",
        "    n, p = input.shape\n",
        "    mask = np.isnan(input)\n",
        "    pattern = defaultdict(list)\n",
        "    for i in range(n):\n",
        "        pattern[tuple(mask[i])].append(i)\n",
        "    \n",
        "    if tuple([False]*p) in pattern:\n",
        "        complete_cases_indicator = True\n",
        "        complete_cases = pattern[tuple([False]*p)]\n",
        "    else:\n",
        "        complete_cases_indicator = False\n",
        "    try:\n",
        "        assert complete_cases_indicator == True\n",
        "    except:\n",
        "        print('no complete cases found, please use MI-NNGP2')\n",
        "        return \n",
        "    \n",
        "    W_std = W_std\n",
        "    b_std = b_std\n",
        "    init_fn, apply_fn, kernel_fn = stax.serial(\n",
        "    stax.Dense(300, W_std=math.sqrt(W_std), b_std=b_std, parameterization=\"standard\"), stax.Relu(),  #stax.Relu()  stax.Erf()\n",
        "    stax.Dense(300, W_std=math.sqrt(W_std), b_std=b_std, parameterization=\"standard\"), stax.Relu(),\n",
        "    stax.Dense(1, W_std=math.sqrt(W_std), b_std=b_std, parameterization=\"standard\")\n",
        "    )\n",
        "\n",
        "    imputation_list = []\n",
        "    for _ in range(number_of_imputation):\n",
        "        key = random.PRNGKey(i*71)\n",
        "        imputation = input.copy()\n",
        "        for mask in list(pattern.keys()):\n",
        "            if list(mask) != [False]*p:\n",
        "                incomplete_cases = pattern[mask]\n",
        "                mask = np.array(list(mask))\n",
        "                train_input = jax.numpy.array(np.transpose(input[complete_cases][:,mask==False]))\n",
        "                test_input = jax.numpy.array(np.transpose(input[complete_cases][:,mask==True]))\n",
        "                train_target = jax.numpy.array(np.transpose(input[incomplete_cases][:,mask==False]))\n",
        "\n",
        "                predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn, train_input, train_target)\n",
        "                nngp_mean, nngp_covariance = predict_fn(x_test=test_input, get='nngp',compute_cov=True)\n",
        "                \n",
        "                intermidate = imputation[incomplete_cases]\n",
        "                if number_of_imputation==1:\n",
        "                    # for single imputation, use mean value as imputation\n",
        "                    intermidate[:,mask==True] = jax.numpy.transpose(nngp_mean)\n",
        "                else:\n",
        "                    # for multiple imputation, draw imputation from posterior distribution\n",
        "                    sampling = np.zeros(nngp_mean.shape)\n",
        "                    for j in range(nngp_mean.shape[1]):\n",
        "                        sampling[:,j] = jax.random.multivariate_normal(key, nngp_mean[:,j], nngp_covariance)\n",
        "                    intermidate[:,mask==True] = jax.numpy.transpose(sampling)\n",
        "                imputation[incomplete_cases] = intermidate\n",
        "\n",
        "        imputation_list.append(imputation)\n",
        "    if number_of_imputation==1:\n",
        "        return imputation_list[0]\n",
        "    else:\n",
        "        return imputation_list"
      ],
      "metadata": {
        "id": "ANTeoSjZf0Kq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MI_NNGP2(input, number_of_imputation=1, burn_in=3, interval=1, W_std=1.0, b_std=0.0):\n",
        "    # W_std is standard deviation of weight parameters\n",
        "    # b_std is standard deviation of bias parameters\n",
        "    # burn_in is burn in period\n",
        "    # interval is sampling interval\n",
        "    n, p = input.shape\n",
        "    mask = np.isnan(input)\n",
        "    pattern = defaultdict(list)\n",
        "    for i in range(n):\n",
        "        pattern[tuple(mask[i])].append(i)\n",
        "    \n",
        "    if tuple([False]*p) in pattern:\n",
        "        initial_imputation = MI_NNGP1(input)\n",
        "    else:\n",
        "        MICE_imputer=IterativeImputer(estimator=BayesianRidge(),skip_complete=True,max_iter=20, tol=0.01,sample_posterior=False,random_state=42)\n",
        "        initial_imputation=MICE_imputer.fit_transform(input)\n",
        "    print('finish initial imputation!')\n",
        "    \n",
        "    W_std = W_std\n",
        "    b_std = b_std\n",
        "    init_fn, apply_fn, kernel_fn = stax.serial(\n",
        "    stax.Dense(300, W_std=math.sqrt(W_std), b_std=b_std, parameterization=\"standard\"), stax.Relu(),  #stax.Relu()  stax.Erf()\n",
        "    stax.Dense(300, W_std=math.sqrt(W_std), b_std=b_std, parameterization=\"standard\"), stax.Relu(),\n",
        "    stax.Dense(1, W_std=math.sqrt(W_std), b_std=b_std, parameterization=\"standard\")\n",
        "    )\n",
        "\n",
        "    imputation = initial_imputation.copy()\n",
        "    imputation_list = []\n",
        "    for i in range(burn_in+number_of_imputation*interval):\n",
        "        key = random.PRNGKey(i*71)\n",
        "        for mask in list(pattern.keys()):\n",
        "            if list(mask) != [False]*p:\n",
        "                incomplete_cases = pattern[mask]\n",
        "                complement_cases = [i for i in list(range(n)) if i not in incomplete_cases]\n",
        "                mask = np.array(list(mask))\n",
        "                train_input = jax.numpy.array(np.transpose(imputation[complement_cases][:,mask==False]))\n",
        "                test_input = jax.numpy.array(np.transpose(imputation[complement_cases][:,mask==True]))\n",
        "                train_target = jax.numpy.array(np.transpose(imputation[incomplete_cases][:,mask==False]))\n",
        "\n",
        "                predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn, train_input, train_target)\n",
        "                nngp_mean, nngp_covariance = predict_fn(x_test=test_input, get='nngp',compute_cov=True)\n",
        "\n",
        "                intermidate = imputation[incomplete_cases]\n",
        "                if number_of_imputation==1:\n",
        "                    # for single imputation, use mean value as imputation\n",
        "                    intermidate[:,mask==True] = jax.numpy.transpose(nngp_mean)\n",
        "                else:\n",
        "                    # for multiple imputation, draw imputation from posterior distribution\n",
        "                    sampling = np.zeros(nngp_mean.shape)\n",
        "                    for j in range(nngp_mean.shape[1]):\n",
        "                        sampling[:,j] = jax.random.multivariate_normal(key, nngp_mean[:,j], nngp_covariance)\n",
        "                    intermidate[:,mask==True] = jax.numpy.transpose(sampling)\n",
        "                imputation[incomplete_cases] = intermidate   \n",
        "\n",
        "        if i>=burn_in and (i+1-burn_in)%interval==0:\n",
        "            imputation_list.append(imputation.copy()) \n",
        "        print('finish epoch {}!'.format(i))\n",
        "\n",
        "    if number_of_imputation==1:\n",
        "        return imputation_list[0]\n",
        "    else:\n",
        "        return imputation_list"
      ],
      "metadata": {
        "id": "PPW2vwJqUf61"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_G_linear(n,p,miss_pat1=[False,False,False,True,False],miss_pat2=[False,False,False,False,True],a0=0,a1=0.1,a2=0.1,a3=0,a4=0.1,a5=0.1,rho=0.1,seed=1,sigma1=0.2,sigma2=0.5):\n",
        "  # obs is observed data matrix\n",
        "  # mis is truth data matrix but masked\n",
        "  # missing_row is indicator of whether a row has missing values\n",
        "  # missing_col is indicator of whether a col has missing values\n",
        "  np.random.seed(seed)\n",
        "  data=np.zeros((n,p))\n",
        "  data[:,0]=np.random.normal(size=(n,),scale=1)        \n",
        "  for col in range(1,p):\n",
        "      data[:,col]=rho*data[:,col-1]+np.random.normal(size=(n,),scale=sigma1)\n",
        "\n",
        "  # split to observed col and missing col\n",
        "  missing_col1=np.array(miss_pat1*int(p/len(miss_pat1)))\n",
        "  missing_col2=np.array(miss_pat2*int(p/len(miss_pat2)))\n",
        "  obs=data[:,np.logical_or(missing_col1,missing_col2)==0]\n",
        "  mis1=data[:,missing_col1==1]\n",
        "  mis2=data[:,missing_col2==1]\n",
        "  truth=np.concatenate((obs,mis1.copy(),mis2.copy()),axis=1)\n",
        "\n",
        "  missing_row1=np.zeros((n,))\n",
        "  missing_row2=np.zeros((n,))\n",
        "  p_miss1 = 0.7\n",
        "  p_miss2 = 0.6\n",
        "  for i in range(n):\n",
        "    missing_row1[i]= np.random.choice(2, 1, p=[1-p_miss1,p_miss1])\n",
        "    missing_row2[i]= np.random.choice(2, 1, p=[1-p_miss2,p_miss2])\n",
        "  mis1[missing_row1==1]=np.nan\n",
        "  mis2[missing_row2==1]=np.nan\n",
        "  return np.concatenate((obs,mis1,mis2),axis=1), truth"
      ],
      "metadata": {
        "id": "K4tFRdyNi7tq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# generate a four-pattern missing data"
      ],
      "metadata": {
        "id": "osM3BE5BjCHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input, truth = data_G_linear(n=200, p=250)"
      ],
      "metadata": {
        "id": "fwFtTR_jjBpS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# conduct imputation"
      ],
      "metadata": {
        "id": "-5oQN8MEj3sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imp1 = MI_NNGP1(input.copy())\n",
        "imp2 = MI_NNGP2(input.copy())\n",
        "mse1 = ((imp1-truth)**2).mean(axis=None) \n",
        "mse2 = ((imp2-truth)**2).mean(axis=None)\n",
        "print('minngp1 mse',mse1)\n",
        "print('minngp2 mse',mse2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMUxI0q3jO4E",
        "outputId": "85f1e651-60c8-4436-85d9-c5ae51372262"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish initial imputation!\n",
            "finish epoch 0!\n",
            "finish epoch 1!\n",
            "finish epoch 2!\n",
            "minngp1 mse 0.016245352536295866\n",
            "minngp2 mse 0.01369883496306891\n"
          ]
        }
      ]
    }
  ]
}